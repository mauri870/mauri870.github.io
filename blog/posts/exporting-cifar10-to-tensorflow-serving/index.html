<!DOCTYPE html>
<html lang="en-us">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		
    <meta name="author" content="Mauri de Souza Nunes">
    <meta name="description" content="The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. In this blog post I&rsquo;ll cover how to export a trained CIFAR-10 tensorflow model to Tensorflow Serving.

">
		<meta name="generator" content="Hugo 0.40.3" />
		<title>How to export the CIFAR10 model to Tensorflow Serving &middot; Mauri870&#39;s dev blog</title>
		<link rel="shortcut icon" href="https://mauri870.github.io/blog/images/favicon.ico">
		<link rel="stylesheet" href="https://mauri870.github.io/blog/css/style.css">
		<link rel="stylesheet" href="https://mauri870.github.io/blog/css/highlight.css">

		
		<link rel="stylesheet" href="https://mauri870.github.io/blog/css/font-awesome.min.css">
		

		
		<link href="https://mauri870.github.io/blog/index.xml" rel="alternate" type="application/rss+xml" title="Mauri870&#39;s dev blog" />
		

		
	</head>

    <body>
       <nav class="main-nav">
  <a href='/'>Home</a>
	
	
		<a href='https://mauri870.github.io/blog/'> <span class="arrow">‚Üê</span>Blog</a>
	
	<a href='https://mauri870.github.io/blog/posts'>Archive</a>
	<a href='https://mauri870.github.io/blog/tags'>Tags</a>
	<a href='https://mauri870.github.io/blog/about'>About</a>

	

	
	<a class="cta" href="https://mauri870.github.io/blog/index.xml">Subscribe</a>
	
</nav>


        <section id="wrapper" class="post">
            <article>
                <header>
                    <h1>
                        How to export the CIFAR10 model to Tensorflow Serving
                    </h1>
                    <h2 class="headline">
                    May 21, 2018 23:26
                    ¬∑ 559 words
                    ¬∑ 3 minute read
                      <span class="tags">
                      
                      
                          
                              <a style="padding-left: 1em;" href="https://mauri870.github.io/blog/tags/cifar10">CIFAR10</a>
                          
                              <a style="padding-left: 1em;" href="https://mauri870.github.io/blog/tags/tensorflow">Tensorflow</a>
                          
                              <a style="padding-left: 1em;" href="https://mauri870.github.io/blog/tags/tensorflow-serving">Tensorflow Serving</a>
                          
                              <a style="padding-left: 1em;" href="https://mauri870.github.io/blog/tags/ai">AI</a>
                          
                              <a style="padding-left: 1em;" href="https://mauri870.github.io/blog/tags/python">Python</a>
                          
                      
                      
                      </span>
                    </h2>
                </header>
                
                  
                    <div id="toc">
                      <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#1-training-the-cifar-10-model">1. Training the CIFAR-10 model</a></li>
<li><a href="#2-exporting-the-model">2. Exporting the model</a></li>
</ul></li>
</ul>
</nav>
                    </div>
                  
                
                <section id="post-body">
                    <p>The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. In this blog post I&rsquo;ll cover how to export a trained CIFAR-10 tensorflow model to Tensorflow Serving.</p>

<p></p>

<hr />

<h2 id="1-training-the-cifar-10-model">1. Training the CIFAR-10 model</h2>

<p>Tensorflow already have a really nice tutorial about the CIFAR10 model, so go ahead and <a href="https://www.tensorflow.org/tutorials/deep_cnn#cifar-10_model">read it first</a>.</p>

<p>When you finish this tutorial, you probably have a trained CIFAR-10 model and a good understanding of how a Convolutional Neural Network works.</p>

<h2 id="2-exporting-the-model">2. Exporting the model</h2>

<p>In order to export the trained model to tensorflow serving, we first need to modify our computational graph to use the tensorflow serving signature.</p>

<p>Save this file as <code>cifar10_saved_model.py</code> in the same directory as the cifar10 files.</p>

<pre><code class="language-python">&quot;&quot;&quot;Tensorflow Serving export script for cifar10
&quot;&quot;&quot;
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
import tensorflow as tf

import cifar10
import cifar10_input

IMAGE_SIZE = cifar10_input.IMAGE_SIZE
NUM_CLASSES = cifar10_input.NUM_CLASSES

FLAGS = tf.app.flags.FLAGS

tf.app.flags.DEFINE_string('checkpoint_dir', '/tmp/cifar10_train',
                           &quot;&quot;&quot;Directory where to read training checkpoints.&quot;&quot;&quot;)
tf.app.flags.DEFINE_string('output_dir', '/tmp/cifar10_export',
                           &quot;&quot;&quot;Directory where to export the model.&quot;&quot;&quot;)
tf.app.flags.DEFINE_integer('model_version', 1,
                            &quot;&quot;&quot;Version number of the model.&quot;&quot;&quot;)

def export():
  with tf.Graph().as_default():
    # Input transformation.
    # Receive a string scalar with the binary contents of the image.
    serialized_tf_example = tf.placeholder(tf.string, name='tf_example')
    feature_configs = {
        'image/encoded': tf.FixedLenFeature(
            shape=[], dtype=tf.string),
    }
    tf_example = tf.parse_single_example(serialized_tf_example, feature_configs)
    encoded_image = tf_example['image/encoded']

    # Decode the image as a 3D tensor ([width, height, channels])
    image = tf.image.decode_image(encoded_image, channels=3)

    # Crop or pad the image to be 24x24x3
    image = tf.image.resize_image_with_crop_or_pad(image, IMAGE_SIZE, IMAGE_SIZE)

    # Cast the image to float32
    image = tf.cast(image, tf.float32)

    # expand dims so we get a 4D tensor [1, 24, 24, 3]
    images = tf.expand_dims(image, 0)

    # Run the tensor through the model (a.k.a inference)
    logits = cifar10.inference(images)

    # Transform output to topK results.
    values, indices = tf.nn.top_k(logits, NUM_CLASSES)

    # Apply softmax so we get normalized values
    normalized_values = tf.nn.softmax(values)

    # Add human readable labels to the integer indices.
    class_descriptions = [
        'airplane',
        'automobile',
        'bird',
        'cat',
        'deer',
        'dog',
        'frog',
        'horse',
        'ship',
        'truck'
    ]
    class_tensor = tf.constant(class_descriptions)
    table = tf.contrib.lookup.index_to_string_table_from_tensor(class_tensor)
    classes = table.lookup(tf.to_int64(indices))

    # Restore variables from training checkpoint.
    variable_averages = tf.train.ExponentialMovingAverage(
        cifar10.MOVING_AVERAGE_DECAY)
    variables_to_restore = variable_averages.variables_to_restore()
    saver = tf.train.Saver(variables_to_restore)

    with tf.Session() as sess:
      # get checkpoint state from checkpoint dir.
      ckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)
      if ckpt and ckpt.model_checkpoint_path:
        # Restores from checkpoint
        saver.restore(sess, ckpt.model_checkpoint_path)
        # Assuming model_checkpoint_path looks something like:
        #   /my-favorite-path/cifar10_train/model.ckpt-0,
        # extract global_step from it.
        global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]
      else:
        print('No checkpoint file found')
        return

      # Export inference model.
      output_path = os.path.join(
          tf.compat.as_bytes(FLAGS.output_dir),
          tf.compat.as_bytes('cifar10'),
          tf.compat.as_bytes(str(FLAGS.model_version)))
      builder = tf.saved_model.builder.SavedModelBuilder(output_path)

      # Build the classification and prediction signatures.
      classify_inputs_tensor_info = tf.saved_model.utils.build_tensor_info(
          serialized_tf_example)
      classes_output_tensor_info = tf.saved_model.utils.build_tensor_info(
          classes)
      scores_output_tensor_info = tf.saved_model.utils.build_tensor_info(normalized_values)

      classification_signature = (
          tf.saved_model.signature_def_utils.build_signature_def(
              inputs={
                  tf.saved_model.signature_constants.CLASSIFY_INPUTS:
                      classify_inputs_tensor_info
              },
              outputs={
                  tf.saved_model.signature_constants.CLASSIFY_OUTPUT_CLASSES:
                      classes_output_tensor_info,
                  tf.saved_model.signature_constants.CLASSIFY_OUTPUT_SCORES:
                      scores_output_tensor_info
              },
              method_name=tf.saved_model.signature_constants.
              CLASSIFY_METHOD_NAME))

      predict_inputs_tensor_info = tf.saved_model.utils.build_tensor_info(encoded_image)
      prediction_signature = (
          tf.saved_model.signature_def_utils.build_signature_def(
              inputs={'images': predict_inputs_tensor_info},
              outputs={
                  'classes': classes_output_tensor_info,
                  'scores': scores_output_tensor_info
              },
              method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME
          ))

      # Add the freezed variables and signatures
      legacy_init_op = tf.group(
          tf.tables_initializer(), name='legacy_init_op')
      builder.add_meta_graph_and_variables(
          sess, [tf.saved_model.tag_constants.SERVING],
          signature_def_map={
              'predict_images':
                  prediction_signature,
              tf.saved_model.signature_constants.
              DEFAULT_SERVING_SIGNATURE_DEF_KEY:
                  classification_signature,
          },
          legacy_init_op=legacy_init_op)

      builder.save()
      print('Successfully exported model to %s' % output_path)

def main(argv=None):  # pylint: disable=unused-argument
  if tf.gfile.Exists(FLAGS.output_dir):
    tf.gfile.DeleteRecursively(FLAGS.output_dir)
  tf.gfile.MakeDirs(FLAGS.output_dir)
  export()

if __name__ == '__main__':
  tf.app.run()
</code></pre>

<blockquote>
<p>Your exported CIFAR10 model will be saved at <code>/tmp/cifar10_export</code>.</p>
</blockquote>

<p>Now you are ready to serve your model with <a href="https://www.tensorflow.org/serving/">Tensorflow Serving</a>. You can follow the inception tutorial <a href="https://www.tensorflow.org/serving/serving_inception#part_0_create_a_docker_image">here</a>, just change your model name to <code>cifar10</code> and adjust the exported folder.</p>

<p>See you again next time üòÑ.</p>
                </section>
            </article>

            

            

            

            <footer id="footer">
    
        <div id="social">

	
	
    <a class="symbol" href="https://www.github.com/mauri870">
        <i class="fa fa-github-square"></i>
    </a>
    


</div>

    
    <p class="small">
    
       ¬© Copyright 2018 <i class="fa fa-heart" aria-hidden="true"></i> Mauri de Souza Nunes
    
    </p>
    <p class="small">
        Powered by <a href="http://www.gohugo.io/">Hugo</a> Theme By <a href="https://github.com/nodejh/hugo-theme-cactus-plus">nodejh</a>
    </p>
</footer>

        </section>

        <script src="https://mauri870.github.io/blog/js/jquery-3.3.1.min.js"></script>
<script src="https://mauri870.github.io/blog/js/main.js"></script>
<script src="https://mauri870.github.io/blog/js/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>







    </body>
</html>
